{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf-idf+log-reg.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Fk_4ZPIbDX_",
        "outputId": "39656a2b-ed6f-4291-943b-9079c9f4e454"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "from catboost import CatBoost\n",
        "from catboost import Pool\n",
        "import nltk\n",
        "import numpy as np\n",
        "\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOhGoN1Jbx02"
      },
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test  = pd.read_csv('test.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIVgv_KZb4_h",
        "outputId": "610e0105-3d1c-4a09-d2f3-cc068cfd469e"
      },
      "source": [
        "train.head(10), test.head(10)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(   id keyword  ...                                               text target\n",
              " 0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              " 1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              " 2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              " 3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              " 4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              " 5   8     NaN  ...  #RockyFire Update => California Hwy. 20 closed...      1\n",
              " 6  10     NaN  ...  #flood #disaster Heavy rain causes flash flood...      1\n",
              " 7  13     NaN  ...  I'm on top of the hill and I can see a fire in...      1\n",
              " 8  14     NaN  ...  There's an emergency evacuation happening now ...      1\n",
              " 9  15     NaN  ...  I'm afraid that the tornado is coming to our a...      1\n",
              " \n",
              " [10 rows x 5 columns],\n",
              "    id keyword location                                               text\n",
              " 0   0     NaN      NaN                 Just happened a terrible car crash\n",
              " 1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              " 2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              " 3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              " 4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan\n",
              " 5  12     NaN      NaN                 We're shaking...It's an earthquake\n",
              " 6  21     NaN      NaN  They'd probably still show more life than Arse...\n",
              " 7  22     NaN      NaN                                  Hey! How are you?\n",
              " 8  27     NaN      NaN                                   What a nice hat?\n",
              " 9  29     NaN      NaN                                          Fuck off!)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Tb9-pXhccgN",
        "outputId": "91733203-45c8-495e-f68c-3243235a7179"
      },
      "source": [
        "print(train.isnull().sum(), train.shape, test.isnull().sum(), test.shape, sep='\\n\\n')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "id             0\n",
            "keyword       61\n",
            "location    2533\n",
            "text           0\n",
            "target         0\n",
            "dtype: int64\n",
            "\n",
            "(7613, 5)\n",
            "\n",
            "id             0\n",
            "keyword       26\n",
            "location    1105\n",
            "text           0\n",
            "dtype: int64\n",
            "\n",
            "(3263, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Pgm3Qe1fWy3"
      },
      "source": [
        "Text preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rya5KSY-ndIw"
      },
      "source": [
        "def preprocess(df):\n",
        "    import re\n",
        "\n",
        "\n",
        "    def lemmatize(sentence):\n",
        "        return ' '.join(map(nltk.stem.WordNetLemmatizer().lemmatize, \n",
        "                            sentence.split()))\n",
        "\n",
        "    def stem(sentence):\n",
        "        return ' '.join(map(nltk.stem.LancasterStemmer().stem, \n",
        "                            sentence.split()))\n",
        "\n",
        "    def sub(sentence):\n",
        "        sentence = re.sub(r\"\\d+\", \"\", sentence)\n",
        "        sentence = re.sub(r\"https?://\\S+|www\\.\\S+\", \"\", sentence)\n",
        "        sentence = re.sub(r\"<.*?>\", \"\", sentence)\n",
        "        sentence = re.sub(r\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", \"\", sentence)\n",
        "        \n",
        "        sentence = re.sub(r\",\", \"\", sentence)\n",
        "        sentence = re.sub(r\"#\", \"\", sentence)\n",
        "        \n",
        "        return sentence\n",
        "\n",
        "    df['text_raw'] = df.text.to_numpy()\n",
        "    df['text']     = df.text.apply(sub).apply(stem).apply(lemmatize)\n",
        "    return df\n",
        "\n",
        "train = preprocess(train)\n",
        "test  = preprocess(test)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "clxjs32J5QiU",
        "outputId": "9b4e43d2-daaf-47c7-c3b1-c0e2b51f7e69"
      },
      "source": [
        "train.loc[:10, ['text', 'text_raw']]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>text_raw</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>our dee ar the reason of thi earthquak may all...</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>forest fir near la rong sask. canad</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>al resid ask to 'shelter in place' ar being no...</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>peopl receiv wildfir evacu ord in californ</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>just got sent thi photo from ruby alask a smok...</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>rockyfir upd =&gt; californ hwy. clos in both dir...</td>\n",
              "      <td>#RockyFire Update =&gt; California Hwy. 20 closed...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>flood disast heavy rain caus flash flood of st...</td>\n",
              "      <td>#flood #disaster Heavy rain causes flash flood...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>i'm on top of the hil and i can see a fir in t...</td>\n",
              "      <td>I'm on top of the hill and I can see a fire in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>there's an emerg evacu hap now in the build ac...</td>\n",
              "      <td>There's an emergency evacuation happening now ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>i'm afraid that the tornado is com to our area...</td>\n",
              "      <td>I'm afraid that the tornado is coming to our a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>three peopl died from the heat wav so far</td>\n",
              "      <td>Three people died from the heat wave so far</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 text                                           text_raw\n",
              "0   our dee ar the reason of thi earthquak may all...  Our Deeds are the Reason of this #earthquake M...\n",
              "1                 forest fir near la rong sask. canad             Forest fire near La Ronge Sask. Canada\n",
              "2   al resid ask to 'shelter in place' ar being no...  All residents asked to 'shelter in place' are ...\n",
              "3          peopl receiv wildfir evacu ord in californ  13,000 people receive #wildfires evacuation or...\n",
              "4   just got sent thi photo from ruby alask a smok...  Just got sent this photo from Ruby #Alaska as ...\n",
              "5   rockyfir upd => californ hwy. clos in both dir...  #RockyFire Update => California Hwy. 20 closed...\n",
              "6   flood disast heavy rain caus flash flood of st...  #flood #disaster Heavy rain causes flash flood...\n",
              "7   i'm on top of the hil and i can see a fir in t...  I'm on top of the hill and I can see a fire in...\n",
              "8   there's an emerg evacu hap now in the build ac...  There's an emergency evacuation happening now ...\n",
              "9   i'm afraid that the tornado is com to our area...  I'm afraid that the tornado is coming to our a...\n",
              "10          three peopl died from the heat wav so far        Three people died from the heat wave so far"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFbBsA1E2d-U"
      },
      "source": [
        "TF-IDF vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ASJ0fvxfQdt",
        "outputId": "295cf32b-e807-4ddc-aca2-419bf14a9049"
      },
      "source": [
        "tfidf = TfidfVectorizer(stop_words='english', \n",
        "                        token_pattern=r'\\b[a-zA-Z]{3,}\\b',\n",
        "                        ngram_range=(1, 1))\n",
        "tfidf.fit(train.text)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
              "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
              "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
              "                smooth_idf=True, stop_words='english', strip_accents=None,\n",
              "                sublinear_tf=False, token_pattern='\\\\b[a-zA-Z]{3,}\\\\b',\n",
              "                tokenizer=None, use_idf=True, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBXrQFhUiHG6"
      },
      "source": [
        "Models for testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ws_80fCiGNa"
      },
      "source": [
        "def get_model(model_name, iterations=100_000):\n",
        "    models = {\n",
        "        'bayes'   :  MultinomialNB(),\n",
        "        'log_reg' :  LogisticRegression(\n",
        "            max_iter = iterations,\n",
        "            solver = 'sag',\n",
        "            fit_intercept = False,\n",
        "            penalty = 'l2',\n",
        "            dual = False,\n",
        "            verbose = 0)\n",
        "    }\n",
        "\n",
        "    return models[model_name]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8UuVNgTsKfp",
        "outputId": "a57e8a14-5147-4d73-d9c8-ca1f2451316e"
      },
      "source": [
        "def fold(X, tfidf_vectorizer, model_name='bayes', iterations=100_000, k=5):\n",
        "    y = X.target\n",
        "    aucs, f1s, models = [], [], []\n",
        "    for train_idx, test_idx in KFold(k, shuffle=True).split(X):\n",
        "        X_train, X__test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "        y_train, y__test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "        model = get_model(model_name)\n",
        "\n",
        "        train_vectors = tfidf_vectorizer.transform(X_train.text)\n",
        "        test__vectors = tfidf_vectorizer.transform(X__test.text)\n",
        "\n",
        "        model.fit(train_vectors, y_train)\n",
        "\n",
        "        y_score = model.predict(test__vectors)\n",
        "\n",
        "        auc = roc_auc_score(y__test, y_score)\n",
        "        f1  = f1_score(y__test, y_score)\n",
        "\n",
        "        aucs.append(auc)\n",
        "        f1s.append(f1)\n",
        "        models.append(model)\n",
        "        print(\"\"\"\n",
        "ROC AUC: {}\n",
        "F1     : {}\n",
        "\"\"\".format(auc, f1))\n",
        "        \n",
        "    print(\"\"\"\n",
        "\n",
        "\n",
        "Mean ROC AUC: {}\n",
        "Mean F1     : {}\n",
        "\"\"\".format(np.mean(aucs), np.mean(f1s)))\n",
        "    \n",
        "    return models\n",
        "\n",
        "\n",
        "models = fold(train, tfidf, model_name='log_reg', k=10, iterations=500_000)    "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ROC AUC: 0.7790074295041369\n",
            "F1     : 0.7436708860759494\n",
            "\n",
            "\n",
            "ROC AUC: 0.7741101918676287\n",
            "F1     : 0.7354838709677419\n",
            "\n",
            "\n",
            "ROC AUC: 0.7663778235228664\n",
            "F1     : 0.7298578199052131\n",
            "\n",
            "\n",
            "ROC AUC: 0.8026039907688843\n",
            "F1     : 0.7711999999999999\n",
            "\n",
            "\n",
            "ROC AUC: 0.773094342251951\n",
            "F1     : 0.7439024390243903\n",
            "\n",
            "\n",
            "ROC AUC: 0.7927028934368383\n",
            "F1     : 0.7569331158238173\n",
            "\n",
            "\n",
            "ROC AUC: 0.7998837547224644\n",
            "F1     : 0.7554806070826308\n",
            "\n",
            "\n",
            "ROC AUC: 0.7755642269563384\n",
            "F1     : 0.7417840375586854\n",
            "\n",
            "\n",
            "ROC AUC: 0.742943803184767\n",
            "F1     : 0.7032967032967032\n",
            "\n",
            "\n",
            "ROC AUC: 0.7719116583213947\n",
            "F1     : 0.730831973898858\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Mean ROC AUC: 0.777820011453727\n",
            "Mean F1     : 0.741244145363399\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v48tLCWUxTlY"
      },
      "source": [
        "Kaggle submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hij18gzjxVDF"
      },
      "source": [
        "test__vectors = tfidf.transform(test.text)\n",
        "train_vectors = tfidf.transform(train.text)\n",
        "\n",
        "model = get_model('log_reg', iterations=300_000)\n",
        "model.fit(train_vectors, train.target)\n",
        "y_scores = model.predict(test__vectors)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMFffqiLx-Qr",
        "outputId": "d382f269-8c8f-4802-e91f-3659d4de5a2f"
      },
      "source": [
        "kaggle_frame = pd.DataFrame({ 'id' : test.id, 'target' : y_scores })\n",
        "kaggle_frame.target.value_counts()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2012\n",
              "1    1251\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9shjDZrvy2WG"
      },
      "source": [
        "kaggle_frame.to_csv('submission.csv', index=False)"
      ],
      "execution_count": 36,
      "outputs": []
    }
  ]
}